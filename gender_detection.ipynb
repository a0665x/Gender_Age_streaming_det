{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac96015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn=frame.copy()\n",
    "    frameHeight=frameOpencvDnn.shape[0]\n",
    "    frameWidth=frameOpencvDnn.shape[1]\n",
    "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections=net.forward()\n",
    "    faceBoxes=[]\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence=detections[0,0,i,2]\n",
    "        if confidence>conf_threshold:\n",
    "            x1=int(detections[0,0,i,3]*frameWidth)\n",
    "            y1=int(detections[0,0,i,4]*frameHeight)\n",
    "            x2=int(detections[0,0,i,5]*frameWidth)\n",
    "            y2=int(detections[0,0,i,6]*frameHeight)\n",
    "            faceBoxes.append([x1,y1,x2,y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn,faceBoxes\n",
    "\n",
    "\n",
    "def plt_plot(x):\n",
    "    ax.hist(x, bins=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96799d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=argparse.ArgumentParser()\n",
    "parser.add_argument('--image')\n",
    "\n",
    "parser.add_argument('--device', default='0,1', type=str, help='设置使用哪些显卡')\n",
    "parser.add_argument('--no_cuda', action='store_true', help='不适用GPU进行训练')\n",
    "args = parser.parse_args(args=['--device', '0',  '--no_cuda'])\n",
    "# args = parser.parse_args()\n",
    "\n",
    "faceProto=\"opencv_face_detector.pbtxt\"\n",
    "faceModel=\"opencv_face_detector_uint8.pb\"\n",
    "ageProto=\"age_deploy.prototxt\"\n",
    "ageModel=\"age_net.caffemodel\"\n",
    "genderProto=\"gender_deploy.prototxt\"\n",
    "genderModel=\"gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList=['Male','Female']\n",
    "\n",
    "faceNet=cv2.dnn.readNet(faceModel,faceProto)\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)\n",
    "\n",
    "video=cv2.VideoCapture(args.image if args.image else 0)\n",
    "padding=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_cunt = 0\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1, 1, 1)\n",
    "count_list = []\n",
    "while True:\n",
    "    hasFrame,frame=video.read()\n",
    "    if not hasFrame:\n",
    "        cv2.waitKey()\n",
    "#         print('no frame')\n",
    "        break\n",
    "    \n",
    "    resultImg,faceBoxes=highlightFace(faceNet,frame)\n",
    "    if not faceBoxes:\n",
    "        cv2.imshow(\"Detecting age and gender\", resultImg)\n",
    "#         print(\"No face detected\")\n",
    "    people_cunt = people_cunt + len(faceBoxes)    \n",
    "    for faceBox in faceBoxes:\n",
    "        face=frame[max(0,faceBox[1]-padding):\n",
    "                   min(faceBox[3]+padding,frame.shape[0]-1),max(0,faceBox[0]-padding)\n",
    "                   :min(faceBox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "        try:\n",
    "            blob=cv2.dnn.blobFromImage(face, 1.0, (228,228), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds=genderNet.forward()\n",
    "        gender=genderList[genderPreds[0].argmax()]\n",
    "        # print(f'Gender: {gender}')\n",
    "\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds=ageNet.forward()\n",
    "        age=ageList[agePreds[0].argmax()]\n",
    "        # print(f'Age: {age[1:-1]} years')\n",
    "\n",
    "        cv2.putText(resultImg, f'{gender}, {age}', (faceBox[0], faceBox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(resultImg, f'people_cunt:{people_cunt}', (50,20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Detecting age and gender\", resultImg)\n",
    "    \n",
    "    count_list.append(people_cunt)\n",
    "    print(count_list)\n",
    "    plt.hist(count_list, bins=10)\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "    people_cunt = 0\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5472e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = [(0, 10), (1, 0), (2, 1), (3, 2), (4, 1), (5, 2), (6, 1), (7, 0), (8, 1), (9, 0), (10, 1), (11, 2), (12, 3), (13, 2), (14, 3), (15, 2), (16, 3), (17, 2), (18, 3), (19, 2), (20, 3), (21, 2), (22, 3),(23, 2)]\n",
    "x = [i for i,j in data]\n",
    "y = [j for i,j in data]\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1, 1, 1)\n",
    "plt.bar(x,y)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa946f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\allen\\.conda\\envs\\tf14\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "x1 = np.linspace(0.0, 5.0)\n",
    "x2 = np.linspace(0.0, 2.0)\n",
    "\n",
    "y1 = np.cos(2 * np.pi * x1) * np.exp(-x1)\n",
    "y2 = np.cos(2 * np.pi * x2)\n",
    "\n",
    "\n",
    "line1, = plt.plot(x1, y1, 'ko-')        # so that we can update data later\n",
    "\n",
    "for i in range(1000):\n",
    "    # update data\n",
    "    line1.set_ydata(np.cos(2 * np.pi * (x1+i*3.14/2) ) * np.exp(-x1) )\n",
    "\n",
    "    # redraw the canvas\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # convert canvas to image\n",
    "    img = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8,\n",
    "            sep='')\n",
    "    img  = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    # img is rgb, convert to opencv's default bgr\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "    # display image with opencv or any operation you like\n",
    "    cv2.imshow(\"plot\",img)\n",
    "\n",
    "    # display camera feed\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow(\"cam\",frame)\n",
    "\n",
    "    k = cv2.waitKey(33) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b849303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
